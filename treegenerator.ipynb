{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class DisplayablePath(object):\n",
    "    display_filename_prefix_middle = '├──'\n",
    "    display_filename_prefix_last = '└──'\n",
    "    display_parent_prefix_middle = '    '\n",
    "    display_parent_prefix_last = '│   '\n",
    "\n",
    "    def __init__(self, path, parent_path, is_last):\n",
    "        self.path = Path(str(path))\n",
    "        self.parent = parent_path\n",
    "        self.is_last = is_last\n",
    "        if self.parent:\n",
    "            self.depth = self.parent.depth + 1\n",
    "        else:\n",
    "            self.depth = 0\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    @classmethod\n",
    "    def make_tree(cls, root, parent=None, is_last=False, criteria=None):\n",
    "        root = Path(str(root))\n",
    "        criteria = criteria or cls._default_criteria\n",
    "\n",
    "        displayable_root = cls(root, parent, is_last)\n",
    "        yield displayable_root\n",
    "\n",
    "        children = sorted(list(path\n",
    "                               for path in root.iterdir()\n",
    "                               if criteria(path)),\n",
    "                          key=lambda s: str(s).lower())\n",
    "        count = 1\n",
    "        for path in children:\n",
    "            is_last = count == len(children)\n",
    "            if path.is_dir():\n",
    "                yield from cls.make_tree(path,\n",
    "                                         parent=displayable_root,\n",
    "                                         is_last=is_last,\n",
    "                                         criteria=criteria)\n",
    "            else:\n",
    "                yield cls(path, displayable_root, is_last)\n",
    "            count += 1\n",
    "            \n",
    "    @classmethod\n",
    "    def _default_criteria(cls, path):\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def displayname(self):\n",
    "        if self.path.is_dir():\n",
    "            return self.path.name + '/'\n",
    "        return self.path.name\n",
    "\n",
    "    def displayable(self):\n",
    "        if self.parent is None:\n",
    "            return self.displayname\n",
    "\n",
    "        _filename_prefix = (self.display_filename_prefix_last\n",
    "                            if self.is_last\n",
    "                            else self.display_filename_prefix_middle)\n",
    "\n",
    "        parts = ['{!s} {!s}'.format(_filename_prefix,\n",
    "                                    self.displayname)]\n",
    "\n",
    "        parent = self.parent\n",
    "        while parent and parent.parent is not None:\n",
    "            parts.append(self.display_parent_prefix_middle\n",
    "                         if parent.is_last\n",
    "                         else self.display_parent_prefix_last)\n",
    "            parent = parent.parent\n",
    "\n",
    "        return ''.join(reversed(parts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE_DETECTION_FINAL_INTERFACE/\n",
      "├── .ipynb_checkpoints/\n",
      "├── cache/\n",
      "│   ├── .ipynb_checkpoints/\n",
      "│   ├── dataset_task1/\n",
      "│   │   └── task1_dataset_.txt\n",
      "│   ├── dataset_task2/\n",
      "│   │   ├── test.txt\n",
      "│   │   ├── train.txt\n",
      "│   │   └── val.txt\n",
      "│   └── dataset_task2_BiLSTM_CRF/\n",
      "│       ├── .ipynb_checkpoints/\n",
      "│       └── ner_dataset.txt\n",
      "├── checkpoints/\n",
      "│   ├── bilstmclassifier.ckpt.data-00000-of-00001\n",
      "│   ├── bilstmclassifier.ckpt.index\n",
      "│   └── checkpoint\n",
      "├── corpus/\n",
      "│   ├── .ipynb_checkpoints/\n",
      "│   ├── __pycache__/\n",
      "│   │   └── Data_Processing.cpython-36.pyc\n",
      "│   └── Data_Processing.py\n",
      "├── glove_embeddings/\n",
      "│   ├── .ipynb_checkpoints/\n",
      "│   ├── glove.6B.100d.txt\n",
      "│   ├── glove.6B.300d.txt\n",
      "│   └── glove.6B.300d.txt.pickle\n",
      "├── Logging/\n",
      "│   ├── .ipynb_checkpoints/\n",
      "│   └── bilstm_classifier_logger/\n",
      "├── models/\n",
      "│   ├── .ipynb_checkpoints/\n",
      "│   ├── binary_classifiers/\n",
      "│   │   ├── .ipynb_checkpoints/\n",
      "│   │   ├── BERT_classifier/\n",
      "│   │   │   ├── .ipynb_checkpoints/\n",
      "│   │   │   │   └── training_model_bert-checkpoint.ipynb\n",
      "│   │   │   ├── __pycache__/\n",
      "│   │   │   │   ├── arguments.cpython-36.pyc\n",
      "│   │   │   │   ├── Data_Loader.cpython-36.pyc\n",
      "│   │   │   │   ├── demo.cpython-36.pyc\n",
      "│   │   │   │   ├── logger.cpython-36.pyc\n",
      "│   │   │   │   ├── PretrainingUtilities.cpython-36.pyc\n",
      "│   │   │   │   ├── SentimentClassifier.cpython-36.pyc\n",
      "│   │   │   │   ├── testing.cpython-36.pyc\n",
      "│   │   │   │   ├── Tokenizer_BERT.cpython-36.pyc\n",
      "│   │   │   │   ├── torch_dataset.cpython-36.pyc\n",
      "│   │   │   │   └── training.cpython-36.pyc\n",
      "│   │   │   ├── arguments.py\n",
      "│   │   │   ├── best_model_state.bin\n",
      "│   │   │   ├── checkpoints_bert/\n",
      "│   │   │   │   └── bertclassifier.ckpt\n",
      "│   │   │   ├── Data_Loader.py\n",
      "│   │   │   ├── demo.py\n",
      "│   │   │   ├── log/\n",
      "│   │   │   │   ├── .ipynb_checkpoints/\n",
      "│   │   │   │   ├── debug.log\n",
      "│   │   │   │   ├── debug.log.2020-08-30\n",
      "│   │   │   │   ├── error.log\n",
      "│   │   │   │   ├── info.log\n",
      "│   │   │   │   ├── info.log.2020-08-30\n",
      "│   │   │   │   └── warn.log\n",
      "│   │   │   ├── logger.py\n",
      "│   │   │   ├── PretrainingUtilities.py\n",
      "│   │   │   ├── SentimentClassifier.py\n",
      "│   │   │   ├── testing.py\n",
      "│   │   │   ├── Tokenizer_BERT.py\n",
      "│   │   │   ├── torch_dataset.py\n",
      "│   │   │   ├── training.py\n",
      "│   │   │   └── training_model_bert.ipynb\n",
      "│   │   ├── BERT_Threshold/\n",
      "│   │   │   ├── .ipynb_checkpoints/\n",
      "│   │   │   │   └── Training_model_thres_BERT-checkpoint.ipynb\n",
      "│   │   │   ├── __pycache__/\n",
      "│   │   │   │   ├── arguments.cpython-36.pyc\n",
      "│   │   │   │   ├── logger.cpython-36.pyc\n",
      "│   │   │   │   ├── models.cpython-36.pyc\n",
      "│   │   │   │   ├── over_sampling.cpython-36.pyc\n",
      "│   │   │   │   ├── threshold_setting.cpython-36.pyc\n",
      "│   │   │   │   └── utilities.cpython-36.pyc\n",
      "│   │   │   ├── arguments.py\n",
      "│   │   │   ├── log/\n",
      "│   │   │   │   ├── debug.log\n",
      "│   │   │   │   ├── error.log\n",
      "│   │   │   │   ├── info.log\n",
      "│   │   │   │   └── warn.log\n",
      "│   │   │   ├── logger.py\n",
      "│   │   │   ├── models.py\n",
      "│   │   │   ├── over_sampling.py\n",
      "│   │   │   ├── threshold_setting.py\n",
      "│   │   │   ├── Training_model_thres_BERT.ipynb\n",
      "│   │   │   └── utilities.py\n",
      "│   │   └── BiLSTM_classifier/\n",
      "│   │       ├── .ipynb_checkpoints/\n",
      "│   │       │   └── training_model_bilstm-checkpoint.ipynb\n",
      "│   │       ├── __pycache__/\n",
      "│   │       │   ├── arguments.cpython-36.pyc\n",
      "│   │       │   ├── Attention.cpython-36.pyc\n",
      "│   │       │   ├── ClassifierModel.cpython-36.pyc\n",
      "│   │       │   ├── demo.cpython-36.pyc\n",
      "│   │       │   ├── logger.cpython-36.pyc\n",
      "│   │       │   ├── test.cpython-36.pyc\n",
      "│   │       │   ├── threshold_setting.cpython-36.pyc\n",
      "│   │       │   └── training.cpython-36.pyc\n",
      "│   │       ├── arguments.py\n",
      "│   │       ├── Attention.py\n",
      "│   │       ├── checkpoints/\n",
      "│   │       ├── checkpoints_bilstm/\n",
      "│   │       │   ├── .ipynb_checkpoints/\n",
      "│   │       │   ├── bilstmclassifier.ckpt.data-00000-of-00001\n",
      "│   │       │   ├── bilstmclassifier.ckpt.index\n",
      "│   │       │   └── checkpoint\n",
      "│   │       ├── ClassifierModel.py\n",
      "│   │       ├── demo.py\n",
      "│   │       ├── log/\n",
      "│   │       │   ├── .ipynb_checkpoints/\n",
      "│   │       │   ├── debug.log\n",
      "│   │       │   ├── debug.log.2020-08-27\n",
      "│   │       │   ├── debug.log.2020-08-28\n",
      "│   │       │   ├── error.log\n",
      "│   │       │   ├── info.log\n",
      "│   │       │   ├── info.log.2020-08-27\n",
      "│   │       │   ├── info.log.2020-08-28\n",
      "│   │       │   └── warn.log\n",
      "│   │       ├── logger.py\n",
      "│   │       ├── main_classifier.py\n",
      "│   │       ├── test.py\n",
      "│   │       ├── threshold_setting.py\n",
      "│   │       ├── Tokenizer/\n",
      "│   │       │   ├── .ipynb_checkpoints/\n",
      "│   │       │   └── tokenizer.pickle\n",
      "│   │       ├── training.py\n",
      "│   │       └── training_model_bilstm.ipynb\n",
      "│   └── ner taggers/\n",
      "│       ├── .ipynb_checkpoints/\n",
      "│       ├── BERT_CRF_tagger/\n",
      "│       │   ├── .ipynb_checkpoints/\n",
      "│       │   │   └── training_bert_crf.py-checkpoint.ipynb\n",
      "│       │   ├── __pycache__/\n",
      "│       │   │   ├── arguments.cpython-36.pyc\n",
      "│       │   │   ├── BERT_CRF_NER.cpython-36.pyc\n",
      "│       │   │   ├── logger.cpython-36.pyc\n",
      "│       │   │   ├── preprocessing_dataset.cpython-36.pyc\n",
      "│       │   │   └── training.cpython-36.pyc\n",
      "│       │   ├── arguments.py\n",
      "│       │   ├── BERT_CRF_NER.py\n",
      "│       │   ├── checkpoints_bert_crf/\n",
      "│       │   │   └── ner_bert_crf_checkpoint.pt\n",
      "│       │   ├── log/\n",
      "│       │   │   ├── debug.log\n",
      "│       │   │   ├── error.log\n",
      "│       │   │   ├── info.log\n",
      "│       │   │   └── warn.log\n",
      "│       │   ├── logger.py\n",
      "│       │   ├── preprocessing_dataset.py\n",
      "│       │   ├── training.py\n",
      "│       │   └── training_bert_crf.py.ipynb\n",
      "│       ├── BERT_tagger/\n",
      "│       │   ├── .ipynb_checkpoints/\n",
      "│       │   │   └── Training_bert-checkpoint.ipynb\n",
      "│       │   ├── __pycache__/\n",
      "│       │   │   ├── arguments.cpython-36.pyc\n",
      "│       │   │   ├── evaluation.cpython-36.pyc\n",
      "│       │   │   ├── example2feature.cpython-36.pyc\n",
      "│       │   │   ├── logger.cpython-36.pyc\n",
      "│       │   │   ├── metrices.cpython-36.pyc\n",
      "│       │   │   ├── preprocessing_dataset.cpython-36.pyc\n",
      "│       │   │   └── training.cpython-36.pyc\n",
      "│       │   ├── arguments.py\n",
      "│       │   ├── checkpoints_bert_tagger/\n",
      "│       │   │   └── ner_bert_checkpoint.pt\n",
      "│       │   ├── log/\n",
      "│       │   │   ├── debug.log\n",
      "│       │   │   ├── error.log\n",
      "│       │   │   ├── info.log\n",
      "│       │   │   └── warn.log\n",
      "│       │   ├── logger.py\n",
      "│       │   ├── preprocessing_dataset.py\n",
      "│       │   ├── pytorch-pretrained-BERT/\n",
      "│       │   │   ├── .circleci/\n",
      "│       │   │   │   ├── config.yml\n",
      "│       │   │   │   └── deploy.sh\n",
      "│       │   │   ├── .coveragerc\n",
      "│       │   │   ├── .git/\n",
      "│       │   │   │   ├── branches/\n",
      "│       │   │   │   ├── config\n",
      "│       │   │   │   ├── description\n",
      "│       │   │   │   ├── HEAD\n",
      "│       │   │   │   ├── hooks/\n",
      "│       │   │   │   │   ├── applypatch-msg.sample\n",
      "│       │   │   │   │   ├── commit-msg.sample\n",
      "│       │   │   │   │   ├── fsmonitor-watchman.sample\n",
      "│       │   │   │   │   ├── post-update.sample\n",
      "│       │   │   │   │   ├── pre-applypatch.sample\n",
      "│       │   │   │   │   ├── pre-commit.sample\n",
      "│       │   │   │   │   ├── pre-push.sample\n",
      "│       │   │   │   │   ├── pre-rebase.sample\n",
      "│       │   │   │   │   ├── pre-receive.sample\n",
      "│       │   │   │   │   ├── prepare-commit-msg.sample\n",
      "│       │   │   │   │   └── update.sample\n",
      "│       │   │   │   ├── index\n",
      "│       │   │   │   ├── info/\n",
      "│       │   │   │   │   └── exclude\n",
      "│       │   │   │   ├── logs/\n",
      "│       │   │   │   │   ├── HEAD\n",
      "│       │   │   │   │   └── refs/\n",
      "│       │   │   │   │       ├── heads/\n",
      "│       │   │   │   │       │   └── master\n",
      "│       │   │   │   │       └── remotes/\n",
      "│       │   │   │   │           └── origin/\n",
      "│       │   │   │   │               └── HEAD\n",
      "│       │   │   │   ├── objects/\n",
      "│       │   │   │   │   ├── info/\n",
      "│       │   │   │   │   └── pack/\n",
      "│       │   │   │   │       ├── pack-f6e7f76094f100d4e8f32066d018bd1a02bbadcf.idx\n",
      "│       │   │   │   │       └── pack-f6e7f76094f100d4e8f32066d018bd1a02bbadcf.pack\n",
      "│       │   │   │   ├── packed-refs\n",
      "│       │   │   │   └── refs/\n",
      "│       │   │   │       ├── heads/\n",
      "│       │   │   │       │   └── master\n",
      "│       │   │   │       ├── remotes/\n",
      "│       │   │   │       │   └── origin/\n",
      "│       │   │   │       │       └── HEAD\n",
      "│       │   │   │       └── tags/\n",
      "│       │   │   ├── .github/\n",
      "│       │   │   │   ├── ISSUE_TEMPLATE/\n",
      "│       │   │   │   │   ├── ---new-benchmark.md\n",
      "│       │   │   │   │   ├── --new-model-addition.md\n",
      "│       │   │   │   │   ├── bug-report.md\n",
      "│       │   │   │   │   ├── feature-request.md\n",
      "│       │   │   │   │   ├── migration.md\n",
      "│       │   │   │   │   └── question-help.md\n",
      "│       │   │   │   ├── stale.yml\n",
      "│       │   │   │   └── workflows/\n",
      "│       │   │   │       ├── github-torch-hub.yml\n",
      "│       │   │   │       ├── self-push.yml\n",
      "│       │   │   │       └── self-scheduled.yml\n",
      "│       │   │   ├── .gitignore\n",
      "│       │   │   ├── codecov.yml\n",
      "│       │   │   ├── CONTRIBUTING.md\n",
      "│       │   │   ├── docker/\n",
      "│       │   │   │   ├── transformers-cpu/\n",
      "│       │   │   │   │   └── Dockerfile\n",
      "│       │   │   │   ├── transformers-gpu/\n",
      "│       │   │   │   │   └── Dockerfile\n",
      "│       │   │   │   ├── transformers-pytorch-cpu/\n",
      "│       │   │   │   │   └── Dockerfile\n",
      "│       │   │   │   ├── transformers-pytorch-gpu/\n",
      "│       │   │   │   │   └── Dockerfile\n",
      "│       │   │   │   ├── transformers-pytorch-tpu/\n",
      "│       │   │   │   │   ├── bert-base-cased.jsonnet\n",
      "│       │   │   │   │   ├── dataset.yaml\n",
      "│       │   │   │   │   ├── docker-entrypoint.sh\n",
      "│       │   │   │   │   └── Dockerfile\n",
      "│       │   │   │   ├── transformers-tensorflow-cpu/\n",
      "│       │   │   │   │   └── Dockerfile\n",
      "│       │   │   │   └── transformers-tensorflow-gpu/\n",
      "│       │   │   │       └── Dockerfile\n",
      "│       │   │   ├── docs/\n",
      "│       │   │   │   ├── Makefile\n",
      "│       │   │   │   ├── README.md\n",
      "│       │   │   │   └── source/\n",
      "│       │   │   │       ├── _static/\n",
      "│       │   │   │       │   ├── css/\n",
      "│       │   │   │       │   │   ├── Calibre-Light.ttf\n",
      "│       │   │   │       │   │   ├── Calibre-Medium.otf\n",
      "│       │   │   │       │   │   ├── Calibre-Regular.otf\n",
      "│       │   │   │       │   │   ├── Calibre-Thin.otf\n",
      "│       │   │   │       │   │   ├── code-snippets.css\n",
      "│       │   │   │       │   │   └── huggingface.css\n",
      "│       │   │   │       │   └── js/\n",
      "│       │   │   │       │       ├── custom.js\n",
      "│       │   │   │       │       └── huggingface_logo.svg\n",
      "│       │   │   │       ├── benchmarks.rst\n",
      "│       │   │   │       ├── bertology.rst\n",
      "│       │   │   │       ├── conf.py\n",
      "│       │   │   │       ├── contributing.md\n",
      "│       │   │   │       ├── converting_tensorflow_models.rst\n",
      "│       │   │   │       ├── custom_datasets.rst\n",
      "│       │   │   │       ├── examples.md\n",
      "│       │   │   │       ├── favicon.ico\n",
      "│       │   │   │       ├── glossary.rst\n",
      "│       │   │   │       ├── imgs/\n",
      "│       │   │   │       │   ├── local_attention_mask.png\n",
      "│       │   │   │       │   ├── ppl_chunked.gif\n",
      "│       │   │   │       │   ├── ppl_full.gif\n",
      "│       │   │   │       │   ├── ppl_sliding.gif\n",
      "│       │   │   │       │   ├── transformers_logo_name.png\n",
      "│       │   │   │       │   ├── warmup_constant_schedule.png\n",
      "│       │   │   │       │   ├── warmup_cosine_hard_restarts_schedule.png\n",
      "│       │   │   │       │   ├── warmup_cosine_schedule.png\n",
      "│       │   │   │       │   ├── warmup_cosine_warm_restarts_schedule.png\n",
      "│       │   │   │       │   └── warmup_linear_schedule.png\n",
      "│       │   │   │       ├── index.rst\n",
      "│       │   │   │       ├── installation.md\n",
      "│       │   │   │       ├── internal/\n",
      "│       │   │   │       │   ├── modeling_utils.rst\n",
      "│       │   │   │       │   ├── pipelines_utils.rst\n",
      "│       │   │   │       │   └── tokenization_utils.rst\n",
      "│       │   │   │       ├── main_classes/\n",
      "│       │   │   │       │   ├── configuration.rst\n",
      "│       │   │   │       │   ├── model.rst\n",
      "│       │   │   │       │   ├── optimizer_schedules.rst\n",
      "│       │   │   │       │   ├── output.rst\n",
      "│       │   │   │       │   ├── pipelines.rst\n",
      "│       │   │   │       │   ├── processors.rst\n",
      "│       │   │   │       │   ├── tokenizer.rst\n",
      "│       │   │   │       │   └── trainer.rst\n",
      "│       │   │   │       ├── migration.md\n",
      "│       │   │   │       ├── model_doc/\n",
      "│       │   │   │       │   ├── albert.rst\n",
      "│       │   │   │       │   ├── auto.rst\n",
      "│       │   │   │       │   ├── bart.rst\n",
      "│       │   │   │       │   ├── bert.rst\n",
      "│       │   │   │       │   ├── camembert.rst\n",
      "│       │   │   │       │   ├── ctrl.rst\n",
      "│       │   │   │       │   ├── dialogpt.rst\n",
      "│       │   │   │       │   ├── distilbert.rst\n",
      "│       │   │   │       │   ├── dpr.rst\n",
      "│       │   │   │       │   ├── electra.rst\n",
      "│       │   │   │       │   ├── encoderdecoder.rst\n",
      "│       │   │   │       │   ├── flaubert.rst\n",
      "│       │   │   │       │   ├── gpt.rst\n",
      "│       │   │   │       │   ├── gpt2.rst\n",
      "│       │   │   │       │   ├── longformer.rst\n",
      "│       │   │   │       │   ├── marian.rst\n",
      "│       │   │   │       │   ├── mbart.rst\n",
      "│       │   │   │       │   ├── mobilebert.rst\n",
      "│       │   │   │       │   ├── pegasus.rst\n",
      "│       │   │   │       │   ├── reformer.rst\n",
      "│       │   │   │       │   ├── retribert.rst\n",
      "│       │   │   │       │   ├── roberta.rst\n",
      "│       │   │   │       │   ├── t5.rst\n",
      "│       │   │   │       │   ├── transformerxl.rst\n",
      "│       │   │   │       │   ├── xlm.rst\n",
      "│       │   │   │       │   ├── xlmroberta.rst\n",
      "│       │   │   │       │   └── xlnet.rst\n",
      "│       │   │   │       ├── model_sharing.rst\n",
      "│       │   │   │       ├── model_summary.rst\n",
      "│       │   │   │       ├── multilingual.rst\n",
      "│       │   │   │       ├── notebooks.md\n",
      "│       │   │   │       ├── perplexity.rst\n",
      "│       │   │   │       ├── philosophy.rst\n",
      "│       │   │   │       ├── preprocessing.rst\n",
      "│       │   │   │       ├── pretrained_models.rst\n",
      "│       │   │   │       ├── quicktour.rst\n",
      "│       │   │   │       ├── serialization.rst\n",
      "│       │   │   │       ├── task_summary.rst\n",
      "│       │   │   │       ├── tokenizer_summary.rst\n",
      "│       │   │   │       └── training.rst\n",
      "│       │   │   ├── examples/\n",
      "│       │   │   │   ├── adversarial/\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_hans.py\n",
      "│       │   │   │   │   └── utils_hans.py\n",
      "│       │   │   │   ├── benchmarking/\n",
      "│       │   │   │   │   ├── plot_csv_file.py\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_benchmark.py\n",
      "│       │   │   │   │   └── run_benchmark_tf.py\n",
      "│       │   │   │   ├── bert-loses-patience/\n",
      "│       │   │   │   │   ├── pabee/\n",
      "│       │   │   │   │   │   ├── __init__.py\n",
      "│       │   │   │   │   │   ├── modeling_pabee_albert.py\n",
      "│       │   │   │   │   │   └── modeling_pabee_bert.py\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_glue_with_pabee.py\n",
      "│       │   │   │   │   └── test_run_glue_with_pabee.py\n",
      "│       │   │   │   ├── bertology/\n",
      "│       │   │   │   │   └── run_bertology.py\n",
      "│       │   │   │   ├── conftest.py\n",
      "│       │   │   │   ├── contrib/\n",
      "│       │   │   │   │   ├── mm-imdb/\n",
      "│       │   │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   │   ├── run_mmimdb.py\n",
      "│       │   │   │   │   │   └── utils_mmimdb.py\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_camembert.py\n",
      "│       │   │   │   │   ├── run_openai_gpt.py\n",
      "│       │   │   │   │   ├── run_swag.py\n",
      "│       │   │   │   │   └── run_transfo_xl.py\n",
      "│       │   │   │   ├── deebert/\n",
      "│       │   │   │   │   ├── entropy_eval.sh\n",
      "│       │   │   │   │   ├── eval_deebert.sh\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_glue_deebert.py\n",
      "│       │   │   │   │   ├── src/\n",
      "│       │   │   │   │   │   ├── __init__.py\n",
      "│       │   │   │   │   │   ├── modeling_highway_bert.py\n",
      "│       │   │   │   │   │   └── modeling_highway_roberta.py\n",
      "│       │   │   │   │   ├── test_glue_deebert.py\n",
      "│       │   │   │   │   └── train_deebert.sh\n",
      "│       │   │   │   ├── distillation/\n",
      "│       │   │   │   │   ├── distiller.py\n",
      "│       │   │   │   │   ├── grouped_batch_sampler.py\n",
      "│       │   │   │   │   ├── lm_seqs_dataset.py\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── requirements.txt\n",
      "│       │   │   │   │   ├── run_squad_w_distillation.py\n",
      "│       │   │   │   │   ├── scripts/\n",
      "│       │   │   │   │   │   ├── binarized_data.py\n",
      "│       │   │   │   │   │   ├── extract.py\n",
      "│       │   │   │   │   │   ├── extract_distilbert.py\n",
      "│       │   │   │   │   │   └── token_counts.py\n",
      "│       │   │   │   │   ├── train.py\n",
      "│       │   │   │   │   ├── training_configs/\n",
      "│       │   │   │   │   │   ├── distilbert-base-cased.json\n",
      "│       │   │   │   │   │   ├── distilbert-base-multilingual-cased.json\n",
      "│       │   │   │   │   │   ├── distilbert-base-uncased.json\n",
      "│       │   │   │   │   │   ├── distilgpt2.json\n",
      "│       │   │   │   │   │   └── distilroberta-base.json\n",
      "│       │   │   │   │   └── utils.py\n",
      "│       │   │   │   ├── language-modeling/\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   └── run_language_modeling.py\n",
      "│       │   │   │   ├── lightning_base.py\n",
      "│       │   │   │   ├── longform-qa/\n",
      "│       │   │   │   │   ├── eli5_app.py\n",
      "│       │   │   │   │   ├── eli5_utils.py\n",
      "│       │   │   │   │   └── README.md\n",
      "│       │   │   │   ├── movement-pruning/\n",
      "│       │   │   │   │   ├── bertarize.py\n",
      "│       │   │   │   │   ├── counts_parameters.py\n",
      "│       │   │   │   │   ├── emmental/\n",
      "│       │   │   │   │   │   ├── __init__.py\n",
      "│       │   │   │   │   │   ├── configuration_bert_masked.py\n",
      "│       │   │   │   │   │   ├── modeling_bert_masked.py\n",
      "│       │   │   │   │   │   └── modules/\n",
      "│       │   │   │   │   │       ├── __init__.py\n",
      "│       │   │   │   │   │       ├── binarizer.py\n",
      "│       │   │   │   │   │       └── masked_nn.py\n",
      "│       │   │   │   │   ├── masked_run_glue.py\n",
      "│       │   │   │   │   ├── masked_run_squad.py\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── requirements.txt\n",
      "│       │   │   │   │   └── Saving_PruneBERT.ipynb\n",
      "│       │   │   │   ├── multiple-choice/\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_multiple_choice.py\n",
      "│       │   │   │   │   ├── run_tf_multiple_choice.py\n",
      "│       │   │   │   │   └── utils_multiple_choice.py\n",
      "│       │   │   │   ├── question-answering/\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_squad.py\n",
      "│       │   │   │   │   ├── run_squad_trainer.py\n",
      "│       │   │   │   │   └── run_tf_squad.py\n",
      "│       │   │   │   ├── README.md\n",
      "│       │   │   │   ├── requirements.txt\n",
      "│       │   │   │   ├── seq2seq/\n",
      "│       │   │   │   │   ├── __init__.py\n",
      "│       │   │   │   │   ├── bertabs/\n",
      "│       │   │   │   │   │   ├── __init__.py\n",
      "│       │   │   │   │   │   ├── configuration_bertabs.py\n",
      "│       │   │   │   │   │   ├── convert_bertabs_original_pytorch_checkpoint.py\n",
      "│       │   │   │   │   │   ├── modeling_bertabs.py\n",
      "│       │   │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   │   ├── requirements.txt\n",
      "│       │   │   │   │   │   ├── run_summarization.py\n",
      "│       │   │   │   │   │   ├── test_utils_summarization.py\n",
      "│       │   │   │   │   │   └── utils_summarization.py\n",
      "│       │   │   │   │   ├── callbacks.py\n",
      "│       │   │   │   │   ├── convert_model_to_fp16.py\n",
      "│       │   │   │   │   ├── distillation.py\n",
      "│       │   │   │   │   ├── download_wmt.py\n",
      "│       │   │   │   │   ├── finetune.py\n",
      "│       │   │   │   │   ├── finetune.sh\n",
      "│       │   │   │   │   ├── finetune_bart_tiny.sh\n",
      "│       │   │   │   │   ├── finetune_pegasus_xsum.sh\n",
      "│       │   │   │   │   ├── finetune_t5.sh\n",
      "│       │   │   │   │   ├── initialization_utils.py\n",
      "│       │   │   │   │   ├── minify_dataset.py\n",
      "│       │   │   │   │   ├── pack_dataset.py\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── romanian_postprocessing.md\n",
      "│       │   │   │   │   ├── run_distiller.sh\n",
      "│       │   │   │   │   ├── run_eval.py\n",
      "│       │   │   │   │   ├── test_bash_script.py\n",
      "│       │   │   │   │   ├── test_data/\n",
      "│       │   │   │   │   │   └── wmt_en_ro/\n",
      "│       │   │   │   │   │       ├── test.source\n",
      "│       │   │   │   │   │       ├── test.target\n",
      "│       │   │   │   │   │       ├── train.source\n",
      "│       │   │   │   │   │       ├── train.target\n",
      "│       │   │   │   │   │       ├── val.source\n",
      "│       │   │   │   │   │       └── val.target\n",
      "│       │   │   │   │   ├── test_seq2seq_examples.py\n",
      "│       │   │   │   │   ├── train_distilbart_cnn.sh\n",
      "│       │   │   │   │   ├── train_distilbart_xsum.sh\n",
      "│       │   │   │   │   ├── train_mbart_cc25_enro.sh\n",
      "│       │   │   │   │   └── utils.py\n",
      "│       │   │   │   ├── test_examples.py\n",
      "│       │   │   │   ├── test_xla_examples.py\n",
      "│       │   │   │   ├── text-classification/\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_glue.py\n",
      "│       │   │   │   │   ├── run_pl.sh\n",
      "│       │   │   │   │   ├── run_pl_glue.py\n",
      "│       │   │   │   │   ├── run_tf_glue.py\n",
      "│       │   │   │   │   └── run_xnli.py\n",
      "│       │   │   │   ├── text-generation/\n",
      "│       │   │   │   │   ├── pplm/\n",
      "│       │   │   │   │   │   ├── imgs/\n",
      "│       │   │   │   │   │   │   ├── headfigure.png\n",
      "│       │   │   │   │   │   │   └── wooly.png\n",
      "│       │   │   │   │   │   ├── pplm_classification_head.py\n",
      "│       │   │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   │   ├── run_pplm.py\n",
      "│       │   │   │   │   │   └── run_pplm_discrim_train.py\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   └── run_generation.py\n",
      "│       │   │   │   ├── token-classification/\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run.sh\n",
      "│       │   │   │   │   ├── run_chunk.sh\n",
      "│       │   │   │   │   ├── run_ner.py\n",
      "│       │   │   │   │   ├── run_pl.sh\n",
      "│       │   │   │   │   ├── run_pl_ner.py\n",
      "│       │   │   │   │   ├── run_pos.sh\n",
      "│       │   │   │   │   ├── run_pos_pl.sh\n",
      "│       │   │   │   │   ├── run_tf_ner.py\n",
      "│       │   │   │   │   ├── scripts/\n",
      "│       │   │   │   │   │   └── preprocess.py\n",
      "│       │   │   │   │   ├── tasks.py\n",
      "│       │   │   │   │   ├── test_ner_examples.py\n",
      "│       │   │   │   │   └── utils_ner.py\n",
      "│       │   │   │   └── xla_spawn.py\n",
      "│       │   │   ├── hubconf.py\n",
      "│       │   │   ├── LICENSE\n",
      "│       │   │   ├── Makefile\n",
      "│       │   │   ├── MANIFEST.in\n",
      "│       │   │   ├── model_cards/\n",
      "│       │   │   │   ├── a-ware/\n",
      "│       │   │   │   │   ├── bart-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-large-squad-classification/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── xlmroberta-squadv2/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── activebus/\n",
      "│       │   │   │   │   ├── BERT-DK_laptop/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── BERT-DK_rest/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── BERT-PT_laptop/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── BERT-PT_rest/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── BERT-XD_Review/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── BERT_Review/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── ahotrod/\n",
      "│       │   │   │   │   ├── albert_xxlargev1_squad2_512/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra_large_discriminator_squad2_512/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta_large_squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── xlnet_large_squad2_512/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── akhooli/\n",
      "│       │   │   │   │   ├── gpt2-small-arabic/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── gpt2-small-arabic-poetry/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── albert-base-v1-README.md\n",
      "│       │   │   │   ├── albert-xxlarge-v2-README.md\n",
      "│       │   │   │   ├── aliosm/\n",
      "│       │   │   │   │   ├── ComVE-distilgpt2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── ComVE-gpt2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── ComVE-gpt2-large/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── ComVE-gpt2-medium/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── allegro/\n",
      "│       │   │   │   │   ├── herbert-klej-cased-tokenizer-v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── herbert-klej-cased-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── allenai/\n",
      "│       │   │   │   │   ├── biomed_roberta_base/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── longformer-base-4096/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── longformer-base-4096-extra.pos.embd.only/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── scibert_scivocab_cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── scibert_scivocab_uncased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── aodiniz/\n",
      "│       │   │   │   │   ├── bert_uncased_L-10_H-512_A-8_cord19-200616/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-10_H-512_A-8_cord19-200616_squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-2_H-512_A-8_cord19-200616/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert_uncased_L-4_H-256_A-4_cord19-200616/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── asafaya/\n",
      "│       │   │   │   │   ├── bert-base-arabic/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-large-arabic/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-medium-arabic/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-mini-arabic/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── aubmindlab/\n",
      "│       │   │   │   │   ├── bert-base-arabert/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-arabertv01/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── bart-large-cnn/\n",
      "│       │   │   │   │   └── README.md\n",
      "│       │   │   │   ├── bart-large-xsum/\n",
      "│       │   │   │   │   └── README.md\n",
      "│       │   │   │   ├── bashar-talafha/\n",
      "│       │   │   │   │   └── multi-dialect-bert-base-arabic/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── bayartsogt/\n",
      "│       │   │   │   │   └── albert-mongolian/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── bert-base-cased-README.md\n",
      "│       │   │   │   ├── bert-base-chinese-README.md\n",
      "│       │   │   │   ├── bert-base-german-cased-README.md\n",
      "│       │   │   │   ├── bert-base-german-dbmdz-cased-README.md\n",
      "│       │   │   │   ├── bert-base-german-dbmdz-uncased-README.md\n",
      "│       │   │   │   ├── bert-base-multilingual-cased-README.md\n",
      "│       │   │   │   ├── bert-base-multilingual-uncased-README.md\n",
      "│       │   │   │   ├── bert-base-uncased-README.md\n",
      "│       │   │   │   ├── bert-large-cased-README.md\n",
      "│       │   │   │   ├── binwang/\n",
      "│       │   │   │   │   └── xlnet-base-cased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── cahya/\n",
      "│       │   │   │   │   ├── bert-base-indonesian-522M/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-small-indonesian-522M/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── roberta-base-indonesian-522M/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── camembert/\n",
      "│       │   │   │   │   ├── camembert-base-ccnet/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── camembert-base-ccnet-4gb/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── camembert-base-oscar-4gb/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── camembert-base-wikipedia-4gb/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── camembert-large/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── camembert-base-README.md\n",
      "│       │   │   │   ├── canwenxu/\n",
      "│       │   │   │   │   └── BERT-of-Theseus-MNLI/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── cedpsam/\n",
      "│       │   │   │   │   └── chatbot_fr/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── chrisliu298/\n",
      "│       │   │   │   │   └── arxiv_ai_gpt2/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── cimm-kzn/\n",
      "│       │   │   │   │   └── rudr-bert/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── clue/\n",
      "│       │   │   │   │   ├── albert_chinese_small/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── albert_chinese_tiny/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta_chinese_3L312_clue_tiny/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta_chinese_base/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta_chinese_large/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── xlnet_chinese_large/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── codegram/\n",
      "│       │   │   │   │   ├── calbert-base-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── calbert-tiny-uncased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── csarron/\n",
      "│       │   │   │   │   ├── bert-base-uncased-squad-v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── mobilebert-uncased-squad-v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── mobilebert-uncased-squad-v2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── roberta-base-squad-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── daigo/\n",
      "│       │   │   │   │   └── bert-base-japanese-sentiment/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── dbmdz/\n",
      "│       │   │   │   │   ├── bert-base-german-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-german-europeana-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-german-europeana-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-german-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-italian-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-italian-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-italian-xxl-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-italian-xxl-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-turkish-128k-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-turkish-128k-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-turkish-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-turkish-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── distilbert-base-turkish-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-base-turkish-cased-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── electra-small-turkish-cased-discriminator/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── DeepPavlov/\n",
      "│       │   │   │   │   ├── bert-base-bg-cs-pl-ru-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-cased-conversational/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-multilingual-cased-sentence/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── rubert-base-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── rubert-base-cased-conversational/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── rubert-base-cased-sentence/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── deepset/\n",
      "│       │   │   │   │   ├── bert-base-german-cased-oldvocab/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-base-squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── minilm-uncased-squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── quora_dedup_bert_base/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-squad2-covid/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── sentence_bert/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── xlm-roberta-large-squad2/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── digitalepidemiologylab/\n",
      "│       │   │   │   │   └── covid-twitter-bert/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── distilbert-base-cased-distilled-squad-README.md\n",
      "│       │   │   │   ├── distilbert-base-multilingual-cased-README.md\n",
      "│       │   │   │   ├── distilbert-base-uncased-distilled-squad-README.md\n",
      "│       │   │   │   ├── distilbert-base-uncased-README.md\n",
      "│       │   │   │   ├── distilgpt2-README.md\n",
      "│       │   │   │   ├── distilroberta-base-README.md\n",
      "│       │   │   │   ├── djstrong/\n",
      "│       │   │   │   │   └── bg_cs_pl_ru_cased_L-12_H-768_A-12/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── dkleczek/\n",
      "│       │   │   │   │   ├── bert-base-polish-cased-v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-polish-uncased-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── dumitrescustefan/\n",
      "│       │   │   │   │   ├── bert-base-romanian-cased-v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-romanian-uncased-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── elgeish/\n",
      "│       │   │   │   │   ├── cs224n-squad2.0-albert-base-v2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── cs224n-squad2.0-albert-large-v2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── cs224n-squad2.0-albert-xxlarge-v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── cs224n-squad2.0-distilbert-base-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── cs224n-squad2.0-roberta-base/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── emilyalsentzer/\n",
      "│       │   │   │   │   ├── Bio_ClinicalBERT/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── Bio_Discharge_Summary_BERT/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── etalab-ia/\n",
      "│       │   │   │   │   └── camembert-base-squadFR-fquad-piaf/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── facebook/\n",
      "│       │   │   │   │   ├── bart-large/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bart-large-cnn/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── fmikaelian/\n",
      "│       │   │   │   │   ├── camembert-base-fquad/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── camembert-base-squad/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── flaubert-base-uncased-squad/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── fran-martinez/\n",
      "│       │   │   │   │   └── scibert_scivocab_cased_ner_jnlpba/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── gaochangkuan/\n",
      "│       │   │   │   │   └── model_dir/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── german-nlp-group/\n",
      "│       │   │   │   │   └── electra-base-german-uncased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── giganticode/\n",
      "│       │   │   │   │   └── StackOBERTflow-comments-small-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── gilf/\n",
      "│       │   │   │   │   ├── french-camembert-postag-model/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── french-postag-model/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── google/\n",
      "│       │   │   │   │   ├── bert_uncased_L-10_H-128_A-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-10_H-256_A-4/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-10_H-512_A-8/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-10_H-768_A-12/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-12_H-128_A-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-12_H-256_A-4/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-12_H-512_A-8/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-12_H-768_A-12/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-2_H-128_A-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-2_H-256_A-4/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-2_H-512_A-8/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-2_H-768_A-12/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-4_H-128_A-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-4_H-256_A-4/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-4_H-512_A-8/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-4_H-768_A-12/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-6_H-128_A-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-6_H-256_A-4/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-6_H-512_A-8/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-6_H-768_A-12/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-8_H-128_A-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-8_H-256_A-4/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-8_H-512_A-8/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert_uncased_L-8_H-768_A-12/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-base-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-base-generator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-large-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-large-generator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-small-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-small-generator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── mobilebert-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── reformer-crime-and-punishment/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── reformer-enwik8/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── gpt2-large-README.md\n",
      "│       │   │   │   ├── gpt2-medium-README.md\n",
      "│       │   │   │   ├── gpt2-README.md\n",
      "│       │   │   │   ├── gpt2-xl-README.md\n",
      "│       │   │   │   ├── gsarti/\n",
      "│       │   │   │   │   ├── biobert-nli/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── covidbert-nli/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── scibert-nli/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── Hate-speech-CNERG/\n",
      "│       │   │   │   │   ├── dehatebert-mono-arabic/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── dehatebert-mono-english/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── dehatebert-mono-french/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── dehatebert-mono-german/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── dehatebert-mono-indonesian/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── dehatebert-mono-italian/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── dehatebert-mono-polish/\n",
      "│       │   │   │   │   │   └── README.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│       │   │   │   │   ├── dehatebert-mono-portugese/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── dehatebert-mono-spanish/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── healx/\n",
      "│       │   │   │   │   ├── gpt-2-pubmed-large/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── gpt-2-pubmed-medium/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── henryk/\n",
      "│       │   │   │   │   ├── bert-base-multilingual-cased-finetuned-dutch-squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-multilingual-cased-finetuned-polish-squad1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-multilingual-cased-finetuned-polish-squad2/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── HooshvareLab/\n",
      "│       │   │   │   │   ├── bert-base-parsbert-armanner-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-parsbert-ner-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-parsbert-peymaner-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-parsbert-uncased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── huggingface/\n",
      "│       │   │   │   │   ├── CodeBERTa-language-id/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── CodeBERTa-small-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── huseinzol05/\n",
      "│       │   │   │   │   ├── albert-base-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── albert-tiny-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-base-discriminator-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-base-generator-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-small-discriminator-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-small-generator-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-117M-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-345M-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-bahasa-summarization-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-bahasa-summarization-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── tiny-bert-bahasa-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── xlnet-base-bahasa-cased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── iarfmoose/\n",
      "│       │   │   │   │   └── t5-base-question-generator/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── illuin/\n",
      "│       │   │   │   │   ├── camembert-base-fquad/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── camembert-large-fquad/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── lepetit/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── ipuneetrathore/\n",
      "│       │   │   │   │   └── bert-base-cased-finetuned-finBERT/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── iuliaturc/\n",
      "│       │   │   │   │   └── bert_uncased_L-2_H-128_A-2/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── ixa-ehu/\n",
      "│       │   │   │   │   └── berteus-base-cased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── jannesg/\n",
      "│       │   │   │   │   ├── bertsson/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_afr_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_nbl_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_nso_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_sot_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_ssw_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_tsn_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_tso_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_ven_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── takalane_xho_roberta/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── takalane_zul_roberta/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── jimregan/\n",
      "│       │   │   │   │   └── BERTreach/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── jme-p/\n",
      "│       │   │   │   │   └── shrugging-grace-tweet-classifier/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── joeddav/\n",
      "│       │   │   │   │   └── bart-large-mnli-yahoo-answers/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── jplu/\n",
      "│       │   │   │   │   ├── tf-camembert-base/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── tf-xlm-r-ner-40-lang/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── tf-xlm-roberta-base/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── tf-xlm-roberta-large/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── julien-c/\n",
      "│       │   │   │   │   ├── bert-xsmall-dummy/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── dummy-unknown/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── EsperBERTo-small/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── EsperBERTo-small-pos/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── KB/\n",
      "│       │   │   │   │   ├── albert-base-swedish-cased-alpha/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-swedish-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-swedish-cased-ner/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── krevas/\n",
      "│       │   │   │   │   ├── finance-koelectra-base-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── finance-koelectra-base-generator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── finance-koelectra-small-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── finance-koelectra-small-generator/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── ktrapeznikov/\n",
      "│       │   │   │   │   ├── albert-xlarge-v2-squad-v2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── biobert_v1.1_pubmed_squad_v2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── scibert_scivocab_uncased_squad_v2/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── lordtt13/\n",
      "│       │   │   │   │   └── emo-mobilebert/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── LorenzoDeMattei/\n",
      "│       │   │   │   │   └── GePpeTto/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── lserinol/\n",
      "│       │   │   │   │   └── bert-turkish-question-answering/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── lvwerra/\n",
      "│       │   │   │   │   ├── bert-imdb/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-imdb/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-imdb-ctrl/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-imdb-pos/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── gpt2-medium-taboo/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── lysandre/\n",
      "│       │   │   │   │   ├── arxiv/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── arxiv-nlp/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── m3hrdadfi/\n",
      "│       │   │   │   │   └── albert-fa-base-v2/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── microsoft/\n",
      "│       │   │   │   │   ├── codebert-base/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── codebert-base-mlm/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── DialoGPT-large/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── DialoGPT-medium/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── DialoGPT-small/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── MiniLM-L12-H384-uncased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── Multilingual-MiniLM-L12-H384/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── monologg/\n",
      "│       │   │   │   │   ├── koelectra-base-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── koelectra-base-generator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── koelectra-small-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── koelectra-small-generator/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── monsoon-nlp/\n",
      "│       │   │   │   │   └── dv-wave/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── MoseliMotsoehli/\n",
      "│       │   │   │   │   ├── TswanaBert/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── zuBERTa/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── moumeneb1/\n",
      "│       │   │   │   │   └── flaubert-base-cased-ecology_crisis/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── mrm8488/\n",
      "│       │   │   │   │   ├── bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-italian-finedtuned-squadv1-it-alfa/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-medium-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-mini-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-multi-cased-finedtuned-xquad-tydiqa-goldp/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-multi-cased-finetuned-xquadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-multi-uncased-finetuned-xquadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-small-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-small-finetuned-typo-detection/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-spanish-cased-finetuned-ner/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-spanish-cased-finetuned-pos/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-spanish-cased-finetuned-pos-syntax/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-tiny-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-uncased-finetuned-qnli/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── chEMBL_smiles_v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── codeBERTaJS/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── CodeBERTaPy/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── distilbert-base-multi-cased-finetuned-typo-detection/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── distilbert-multi-finetuned-for-xqua-on-tydiqa/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── distilroberta-base-finetuned-sentiment/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-base-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-small-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-small-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electricidad-small-discriminator/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electricidad-small-finetuned-squadv1-es/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── GPT-2-finetuned-CORD19/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── GPT-2-finetuned-covid-bio-medrxiv/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-finetuned-recipes-cooking/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-finetuned-recipes-cooking_v2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-imdb-neg/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── gpt2-imdb-neutral/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── longformer-base-4096-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── mobilebert-uncased-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── mobilebert-uncased-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── RoBasquERTa/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-1B-1-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-1B-1-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-large-finetuned-wsc/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── RoBERTinha/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── RuPERTa-base/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── RuPERTa-base-finetuned-ner/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── RuPERTa-base-finetuned-pos/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── RuPERTa-base-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── RuPERTa-base-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── spanbert-base-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── spanbert-base-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── spanbert-base-finetuned-tacred/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── spanbert-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── spanbert-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── spanbert-large-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── spanbert-large-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── spanbert-large-finetuned-tacred/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-break_data/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-break_data-question-retrieval/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-e2m-intent/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-emotion/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-imdb-sentiment/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-question-generation-ap/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-sarcasm-twitter/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-span-sentiment-extraction/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-summarize-news/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-wikiSQL/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-finetuned-wikiSQL-sql-to-en/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-finetuned-emotion/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-finetuned-imdb-sentiment/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-finetuned-quora-for-paraphrasing/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-finetuned-squadv2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-finetuned-wikiSQL/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── TinyBERT-spanish-uncased-finetuned-ner/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── umberto-wikipedia-uncased-v1-finetuned-squadv1-it/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── xlm-multi-finetuned-xquadv1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── Musixmatch/\n",
      "│       │   │   │   │   ├── umberto-commoncrawl-cased-v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── umberto-wikipedia-uncased-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── mys/\n",
      "│       │   │   │   │   └── electra-base-turkish-cased-ner/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── NeuML/\n",
      "│       │   │   │   │   ├── bert-small-cord19/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-small-cord19-squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-small-cord19qa/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── neuralmind/\n",
      "│       │   │   │   │   ├── bert-base-portuguese-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-large-portuguese-cased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── neuraly/\n",
      "│       │   │   │   │   └── bert-base-italian-cased-sentiment/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── nghuyong/\n",
      "│       │   │   │   │   ├── ernie-1.0/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── ernie-2.0-en/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── ernie-2.0-large-en/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── ernie-tiny/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── NLP4H/\n",
      "│       │   │   │   │   └── ms_bert/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── nlpaueb/\n",
      "│       │   │   │   │   └── bert-base-greek-uncased-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── nlptown/\n",
      "│       │   │   │   │   └── bert-base-multilingual-uncased-sentiment/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── Norod78/\n",
      "│       │   │   │   │   └── hewiki-articles-distilGPT2py-il/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── nyu-mll/\n",
      "│       │   │   │   │   ├── roberta-base-100M-1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-100M-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-100M-3/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-10M-1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-10M-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-10M-3/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-1B-1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-1B-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-base-1B-3/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-med-small-1M-1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-med-small-1M-2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── roberta-med-small-1M-3/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── roberta_1M_to_1B/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── oliverguhr/\n",
      "│       │   │   │   │   └── german-sentiment-bert/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── patrickvonplaten/\n",
      "│       │   │   │   │   ├── bert2bert-cnn_dailymail-fp16/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert2gpt2-cnn_dailymail-fp16/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── pierreguillou/\n",
      "│       │   │   │   │   └── gpt2-small-portuguese/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── pradhyra/\n",
      "│       │   │   │   │   └── AWSBlogBert/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── pranavpsv/\n",
      "│       │   │   │   │   └── gpt2-genre-story-generator/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── ramsrigouthamg/\n",
      "│       │   │   │   │   └── t5_paraphraser/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── rdenadai/\n",
      "│       │   │   │   │   └── BR_BERTo/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── redewiedergabe/\n",
      "│       │   │   │   │   └── bert-base-historical-german-rw-cased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── roberta-base-README.md\n",
      "│       │   │   │   ├── roberta-large-mnli-README.md\n",
      "│       │   │   │   ├── roberta-large-README.md\n",
      "│       │   │   │   ├── rohanrajpal/\n",
      "│       │   │   │   │   ├── bert-base-codemixed-uncased-sentiment/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-multilingual-codemixed-cased-sentiment/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── savasy/\n",
      "│       │   │   │   │   ├── bert-base-turkish-ner-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-turkish-sentiment-cased/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-turkish-squad/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-turkish-text-classification/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── schmidek/\n",
      "│       │   │   │   │   └── electra-small-cased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── seiya/\n",
      "│       │   │   │   │   └── oubiobert-base-uncased/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── sentence-transformers/\n",
      "│       │   │   │   │   ├── bert-base-nli-cls-token/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-nli-max-tokens/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-nli-mean-tokens/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── severinsimmler/\n",
      "│       │   │   │   │   └── literary-german-bert/\n",
      "│       │   │   │   │       ├── kfold.png\n",
      "│       │   │   │   │       ├── prosa-jahre.png\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── seyonec/\n",
      "│       │   │   │   │   └── ChemBERTa-zinc-base-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── shoarora/\n",
      "│       │   │   │   │   ├── alectra-small-owt/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── electra-small-owt/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── shrugging-grace/\n",
      "│       │   │   │   │   └── tweetclassifier/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── SparkBeyond/\n",
      "│       │   │   │   │   └── roberta-large-sts-b/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── spentaur/\n",
      "│       │   │   │   │   └── yelp/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── surajp/\n",
      "│       │   │   │   │   ├── albert-base-sanskrit/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── RoBERTa-hindi-guj-san/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── SanBERTa/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── T-Systems-onsite/\n",
      "│       │   │   │   │   └── bert-german-dbmdz-uncased-sentence-stsb/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── t5-11b-README.md\n",
      "│       │   │   │   ├── t5-3b-README.md\n",
      "│       │   │   │   ├── t5-base-README.md\n",
      "│       │   │   │   ├── t5-large-README.md\n",
      "│       │   │   │   ├── t5-small-README.md\n",
      "│       │   │   │   ├── tblard/\n",
      "│       │   │   │   │   └── tf-allocine/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── Tereveni-AI/\n",
      "│       │   │   │   │   └── gpt2-124M-uk-fiction/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── tuner007/\n",
      "│       │   │   │   │   └── t5_abs_qa/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── TurkuNLP/\n",
      "│       │   │   │   │   ├── bert-base-finnish-cased-v1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── bert-base-finnish-uncased-v1/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── twmkn9/\n",
      "│       │   │   │   │   ├── albert-base-v2-squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── bert-base-uncased-squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── distilbert-base-uncased-squad2/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── distilroberta-base-squad2/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── unideeplearning/\n",
      "│       │   │   │   │   └── polibert_sa/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── urduhack/\n",
      "│       │   │   │   │   └── roberta-urdu-small/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── valhalla/\n",
      "│       │   │   │   │   ├── bart-large-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── electra-base-discriminator-finetuned_squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── longformer-base-4096-finetuned-squadv1/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-e2e-qg/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-qa-qg-hl/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-qg-hl/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-base-squad/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-samll-qg-prepend/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-e2e-qg/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── t5-small-qa-qg-hl/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── t5-small-qg-hl/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── Vamsi/\n",
      "│       │   │   │   │   └── T5_Paraphrase_Paws/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── VictorSanh/\n",
      "│       │   │   │   │   └── roberta-base-finetuned-yelp-polarity/\n",
      "│       │   │   │   │       └── README.md\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│       │   │   │   ├── ViktorAlm/\n",
      "│       │   │   │   │   └── electra-base-norwegian-uncased-discriminator/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── voidful/\n",
      "│       │   │   │   │   ├── albert_chinese_base/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── albert_chinese_large/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── albert_chinese_small/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── albert_chinese_tiny/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   ├── albert_chinese_xlarge/\n",
      "│       │   │   │   │   │   └── README.md\n",
      "│       │   │   │   │   └── albert_chinese_xxlarge/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── wptoux/\n",
      "│       │   │   │   │   └── albert-chinese-large-qa/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── xlm-mlm-en-2048-README.md\n",
      "│       │   │   │   ├── xlm-roberta-base-README.md\n",
      "│       │   │   │   ├── xlm-roberta-large-finetuned-conll03-german-README.md\n",
      "│       │   │   │   ├── yjernite/\n",
      "│       │   │   │   │   └── bart_eli5/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   ├── youscan/\n",
      "│       │   │   │   │   └── ukr-roberta-base/\n",
      "│       │   │   │   │       └── README.md\n",
      "│       │   │   │   └── yuvraj/\n",
      "│       │   │   │       ├── summarizer-cnndm/\n",
      "│       │   │   │       │   └── README.md\n",
      "│       │   │   │       └── xSumm/\n",
      "│       │   │   │           └── README.md\n",
      "│       │   │   ├── notebooks/\n",
      "│       │   │   │   ├── 01-training-tokenizers.ipynb\n",
      "│       │   │   │   ├── 02-transformers.ipynb\n",
      "│       │   │   │   ├── 03-pipelines.ipynb\n",
      "│       │   │   │   ├── 04-onnx-export.ipynb\n",
      "│       │   │   │   ├── 05-benchmark.ipynb\n",
      "│       │   │   │   └── README.md\n",
      "│       │   │   ├── README.md\n",
      "│       │   │   ├── setup.cfg\n",
      "│       │   │   ├── setup.py\n",
      "│       │   │   ├── src/\n",
      "│       │   │   │   └── transformers/\n",
      "│       │   │   │       ├── __init__.py\n",
      "│       │   │   │       ├── activations.py\n",
      "│       │   │   │       ├── benchmark/\n",
      "│       │   │   │       │   ├── __init__.py\n",
      "│       │   │   │       │   ├── benchmark.py\n",
      "│       │   │   │       │   ├── benchmark_args.py\n",
      "│       │   │   │       │   ├── benchmark_args_tf.py\n",
      "│       │   │   │       │   ├── benchmark_args_utils.py\n",
      "│       │   │   │       │   ├── benchmark_tf.py\n",
      "│       │   │   │       │   └── benchmark_utils.py\n",
      "│       │   │   │       ├── commands/\n",
      "│       │   │   │       │   ├── __init__.py\n",
      "│       │   │   │       │   ├── convert.py\n",
      "│       │   │   │       │   ├── download.py\n",
      "│       │   │   │       │   ├── env.py\n",
      "│       │   │   │       │   ├── run.py\n",
      "│       │   │   │       │   ├── serving.py\n",
      "│       │   │   │       │   ├── train.py\n",
      "│       │   │   │       │   ├── transformers_cli.py\n",
      "│       │   │   │       │   └── user.py\n",
      "│       │   │   │       ├── configuration_albert.py\n",
      "│       │   │   │       ├── configuration_auto.py\n",
      "│       │   │   │       ├── configuration_bart.py\n",
      "│       │   │   │       ├── configuration_bert.py\n",
      "│       │   │   │       ├── configuration_camembert.py\n",
      "│       │   │   │       ├── configuration_ctrl.py\n",
      "│       │   │   │       ├── configuration_distilbert.py\n",
      "│       │   │   │       ├── configuration_dpr.py\n",
      "│       │   │   │       ├── configuration_electra.py\n",
      "│       │   │   │       ├── configuration_encoder_decoder.py\n",
      "│       │   │   │       ├── configuration_flaubert.py\n",
      "│       │   │   │       ├── configuration_gpt2.py\n",
      "│       │   │   │       ├── configuration_longformer.py\n",
      "│       │   │   │       ├── configuration_marian.py\n",
      "│       │   │   │       ├── configuration_mbart.py\n",
      "│       │   │   │       ├── configuration_mmbt.py\n",
      "│       │   │   │       ├── configuration_mobilebert.py\n",
      "│       │   │   │       ├── configuration_openai.py\n",
      "│       │   │   │       ├── configuration_pegasus.py\n",
      "│       │   │   │       ├── configuration_reformer.py\n",
      "│       │   │   │       ├── configuration_retribert.py\n",
      "│       │   │   │       ├── configuration_roberta.py\n",
      "│       │   │   │       ├── configuration_t5.py\n",
      "│       │   │   │       ├── configuration_transfo_xl.py\n",
      "│       │   │   │       ├── configuration_utils.py\n",
      "│       │   │   │       ├── configuration_xlm.py\n",
      "│       │   │   │       ├── configuration_xlm_roberta.py\n",
      "│       │   │   │       ├── configuration_xlnet.py\n",
      "│       │   │   │       ├── convert_albert_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_bart_original_pytorch_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_bert_original_tf2_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_bert_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_bert_pytorch_checkpoint_to_original_tf.py\n",
      "│       │   │   │       ├── convert_dialogpt_original_pytorch_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_dpr_original_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_electra_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_gpt2_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_graph_to_onnx.py\n",
      "│       │   │   │       ├── convert_longformer_original_pytorch_lightning_to_pytorch.py\n",
      "│       │   │   │       ├── convert_marian_to_pytorch.py\n",
      "│       │   │   │       ├── convert_mbart_original_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_mobilebert_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_openai_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_pegasus_tf_to_pytorch.py\n",
      "│       │   │   │       ├── convert_pytorch_checkpoint_to_tf2.py\n",
      "│       │   │   │       ├── convert_reformer_trax_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_roberta_original_pytorch_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_t5_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_transfo_xl_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_xlm_original_pytorch_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── convert_xlnet_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── data/\n",
      "│       │   │   │       │   ├── __init__.py\n",
      "│       │   │   │       │   ├── data_collator.py\n",
      "│       │   │   │       │   ├── datasets/\n",
      "│       │   │   │       │   │   ├── __init__.py\n",
      "│       │   │   │       │   │   ├── glue.py\n",
      "│       │   │   │       │   │   ├── language_modeling.py\n",
      "│       │   │   │       │   │   └── squad.py\n",
      "│       │   │   │       │   ├── metrics/\n",
      "│       │   │   │       │   │   ├── __init__.py\n",
      "│       │   │   │       │   │   └── squad_metrics.py\n",
      "│       │   │   │       │   ├── processors/\n",
      "│       │   │   │       │   │   ├── __init__.py\n",
      "│       │   │   │       │   │   ├── glue.py\n",
      "│       │   │   │       │   │   ├── squad.py\n",
      "│       │   │   │       │   │   ├── utils.py\n",
      "│       │   │   │       │   │   └── xnli.py\n",
      "│       │   │   │       │   └── test_generation_utils.py\n",
      "│       │   │   │       ├── file_utils.py\n",
      "│       │   │   │       ├── generation_tf_utils.py\n",
      "│       │   │   │       ├── generation_utils.py\n",
      "│       │   │   │       ├── hf_api.py\n",
      "│       │   │   │       ├── hf_argparser.py\n",
      "│       │   │   │       ├── integrations.py\n",
      "│       │   │   │       ├── modelcard.py\n",
      "│       │   │   │       ├── modeling_albert.py\n",
      "│       │   │   │       ├── modeling_auto.py\n",
      "│       │   │   │       ├── modeling_bart.py\n",
      "│       │   │   │       ├── modeling_bert.py\n",
      "│       │   │   │       ├── modeling_camembert.py\n",
      "│       │   │   │       ├── modeling_ctrl.py\n",
      "│       │   │   │       ├── modeling_distilbert.py\n",
      "│       │   │   │       ├── modeling_dpr.py\n",
      "│       │   │   │       ├── modeling_electra.py\n",
      "│       │   │   │       ├── modeling_encoder_decoder.py\n",
      "│       │   │   │       ├── modeling_flaubert.py\n",
      "│       │   │   │       ├── modeling_gpt2.py\n",
      "│       │   │   │       ├── modeling_longformer.py\n",
      "│       │   │   │       ├── modeling_marian.py\n",
      "│       │   │   │       ├── modeling_mbart.py\n",
      "│       │   │   │       ├── modeling_mmbt.py\n",
      "│       │   │   │       ├── modeling_mobilebert.py\n",
      "│       │   │   │       ├── modeling_openai.py\n",
      "│       │   │   │       ├── modeling_outputs.py\n",
      "│       │   │   │       ├── modeling_pegasus.py\n",
      "│       │   │   │       ├── modeling_reformer.py\n",
      "│       │   │   │       ├── modeling_retribert.py\n",
      "│       │   │   │       ├── modeling_roberta.py\n",
      "│       │   │   │       ├── modeling_t5.py\n",
      "│       │   │   │       ├── modeling_tf_albert.py\n",
      "│       │   │   │       ├── modeling_tf_auto.py\n",
      "│       │   │   │       ├── modeling_tf_bert.py\n",
      "│       │   │   │       ├── modeling_tf_camembert.py\n",
      "│       │   │   │       ├── modeling_tf_ctrl.py\n",
      "│       │   │   │       ├── modeling_tf_distilbert.py\n",
      "│       │   │   │       ├── modeling_tf_electra.py\n",
      "│       │   │   │       ├── modeling_tf_flaubert.py\n",
      "│       │   │   │       ├── modeling_tf_gpt2.py\n",
      "│       │   │   │       ├── modeling_tf_longformer.py\n",
      "│       │   │   │       ├── modeling_tf_mobilebert.py\n",
      "│       │   │   │       ├── modeling_tf_openai.py\n",
      "│       │   │   │       ├── modeling_tf_outputs.py\n",
      "│       │   │   │       ├── modeling_tf_pytorch_utils.py\n",
      "│       │   │   │       ├── modeling_tf_roberta.py\n",
      "│       │   │   │       ├── modeling_tf_t5.py\n",
      "│       │   │   │       ├── modeling_tf_transfo_xl.py\n",
      "│       │   │   │       ├── modeling_tf_transfo_xl_utilities.py\n",
      "│       │   │   │       ├── modeling_tf_utils.py\n",
      "│       │   │   │       ├── modeling_tf_xlm.py\n",
      "│       │   │   │       ├── modeling_tf_xlm_roberta.py\n",
      "│       │   │   │       ├── modeling_tf_xlnet.py\n",
      "│       │   │   │       ├── modeling_transfo_xl.py\n",
      "│       │   │   │       ├── modeling_transfo_xl_utilities.py\n",
      "│       │   │   │       ├── modeling_utils.py\n",
      "│       │   │   │       ├── modeling_xlm.py\n",
      "│       │   │   │       ├── modeling_xlm_roberta.py\n",
      "│       │   │   │       ├── modeling_xlnet.py\n",
      "│       │   │   │       ├── optimization.py\n",
      "│       │   │   │       ├── optimization_tf.py\n",
      "│       │   │   │       ├── pipelines.py\n",
      "│       │   │   │       ├── testing_utils.py\n",
      "│       │   │   │       ├── tokenization_albert.py\n",
      "│       │   │   │       ├── tokenization_auto.py\n",
      "│       │   │   │       ├── tokenization_bart.py\n",
      "│       │   │   │       ├── tokenization_bert.py\n",
      "│       │   │   │       ├── tokenization_bert_japanese.py\n",
      "│       │   │   │       ├── tokenization_camembert.py\n",
      "│       │   │   │       ├── tokenization_ctrl.py\n",
      "│       │   │   │       ├── tokenization_distilbert.py\n",
      "│       │   │   │       ├── tokenization_dpr.py\n",
      "│       │   │   │       ├── tokenization_electra.py\n",
      "│       │   │   │       ├── tokenization_flaubert.py\n",
      "│       │   │   │       ├── tokenization_gpt2.py\n",
      "│       │   │   │       ├── tokenization_longformer.py\n",
      "│       │   │   │       ├── tokenization_marian.py\n",
      "│       │   │   │       ├── tokenization_mbart.py\n",
      "│       │   │   │       ├── tokenization_mobilebert.py\n",
      "│       │   │   │       ├── tokenization_openai.py\n",
      "│       │   │   │       ├── tokenization_pegasus.py\n",
      "│       │   │   │       ├── tokenization_reformer.py\n",
      "│       │   │   │       ├── tokenization_retribert.py\n",
      "│       │   │   │       ├── tokenization_roberta.py\n",
      "│       │   │   │       ├── tokenization_t5.py\n",
      "│       │   │   │       ├── tokenization_transfo_xl.py\n",
      "│       │   │   │       ├── tokenization_utils.py\n",
      "│       │   │   │       ├── tokenization_utils_base.py\n",
      "│       │   │   │       ├── tokenization_utils_fast.py\n",
      "│       │   │   │       ├── tokenization_xlm.py\n",
      "│       │   │   │       ├── tokenization_xlm_roberta.py\n",
      "│       │   │   │       ├── tokenization_xlnet.py\n",
      "│       │   │   │       ├── trainer.py\n",
      "│       │   │   │       ├── trainer_tf.py\n",
      "│       │   │   │       ├── trainer_utils.py\n",
      "│       │   │   │       ├── training_args.py\n",
      "│       │   │   │       └── training_args_tf.py\n",
      "│       │   │   ├── templates/\n",
      "│       │   │   │   ├── adding_a_new_example_script/\n",
      "│       │   │   │   │   ├── README.md\n",
      "│       │   │   │   │   ├── run_xxx.py\n",
      "│       │   │   │   │   └── utils_xxx.py\n",
      "│       │   │   │   └── adding_a_new_model/\n",
      "│       │   │   │       ├── configuration_xxx.py\n",
      "│       │   │   │       ├── convert_xxx_original_tf_checkpoint_to_pytorch.py\n",
      "│       │   │   │       ├── modeling_tf_xxx.py\n",
      "│       │   │   │       ├── modeling_xxx.py\n",
      "│       │   │   │       ├── README.md\n",
      "│       │   │   │       ├── tests/\n",
      "│       │   │   │       │   ├── test_modeling_tf_xxx.py\n",
      "│       │   │   │       │   ├── test_modeling_xxx.py\n",
      "│       │   │   │       │   └── test_tokenization_xxx.py\n",
      "│       │   │   │       └── tokenization_xxx.py\n",
      "│       │   │   ├── tests/\n",
      "│       │   │   │   ├── __init__.py\n",
      "│       │   │   │   ├── conftest.py\n",
      "│       │   │   │   ├── fixtures/\n",
      "│       │   │   │   │   ├── dummy-config.json\n",
      "│       │   │   │   │   ├── empty.txt\n",
      "│       │   │   │   │   ├── input.txt\n",
      "│       │   │   │   │   ├── sample_text.txt\n",
      "│       │   │   │   │   ├── spiece.model\n",
      "│       │   │   │   │   ├── test_sentencepiece.model\n",
      "│       │   │   │   │   └── tests_samples/\n",
      "│       │   │   │   │       ├── .gitignore\n",
      "│       │   │   │   │       ├── GermEval/\n",
      "│       │   │   │   │       │   ├── dev.txt\n",
      "│       │   │   │   │       │   ├── labels.txt\n",
      "│       │   │   │   │       │   └── train.txt\n",
      "│       │   │   │   │       ├── MRPC/\n",
      "│       │   │   │   │       │   ├── dev.tsv\n",
      "│       │   │   │   │       │   └── train.tsv\n",
      "│       │   │   │   │       ├── SQUAD/\n",
      "│       │   │   │   │       │   ├── dev-v2.0.json\n",
      "│       │   │   │   │       │   └── train-v2.0.json\n",
      "│       │   │   │   │       └── STS-B/\n",
      "│       │   │   │   │           ├── dev.tsv\n",
      "│       │   │   │   │           └── train.tsv\n",
      "│       │   │   │   ├── test_activations.py\n",
      "│       │   │   │   ├── test_benchmark.py\n",
      "│       │   │   │   ├── test_benchmark_tf.py\n",
      "│       │   │   │   ├── test_configuration_auto.py\n",
      "│       │   │   │   ├── test_configuration_common.py\n",
      "│       │   │   │   ├── test_doc_samples.py\n",
      "│       │   │   │   ├── test_hf_api.py\n",
      "│       │   │   │   ├── test_hf_argparser.py\n",
      "│       │   │   │   ├── test_model_card.py\n",
      "│       │   │   │   ├── test_modeling_albert.py\n",
      "│       │   │   │   ├── test_modeling_auto.py\n",
      "│       │   │   │   ├── test_modeling_bart.py\n",
      "│       │   │   │   ├── test_modeling_bert.py\n",
      "│       │   │   │   ├── test_modeling_camembert.py\n",
      "│       │   │   │   ├── test_modeling_common.py\n",
      "│       │   │   │   ├── test_modeling_ctrl.py\n",
      "│       │   │   │   ├── test_modeling_distilbert.py\n",
      "│       │   │   │   ├── test_modeling_dpr.py\n",
      "│       │   │   │   ├── test_modeling_electra.py\n",
      "│       │   │   │   ├── test_modeling_encoder_decoder.py\n",
      "│       │   │   │   ├── test_modeling_flaubert.py\n",
      "│       │   │   │   ├── test_modeling_gpt2.py\n",
      "│       │   │   │   ├── test_modeling_longformer.py\n",
      "│       │   │   │   ├── test_modeling_marian.py\n",
      "│       │   │   │   ├── test_modeling_mbart.py\n",
      "│       │   │   │   ├── test_modeling_mobilebert.py\n",
      "│       │   │   │   ├── test_modeling_openai.py\n",
      "│       │   │   │   ├── test_modeling_pegasus.py\n",
      "│       │   │   │   ├── test_modeling_reformer.py\n",
      "│       │   │   │   ├── test_modeling_roberta.py\n",
      "│       │   │   │   ├── test_modeling_t5.py\n",
      "│       │   │   │   ├── test_modeling_tf_albert.py\n",
      "│       │   │   │   ├── test_modeling_tf_auto.py\n",
      "│       │   │   │   ├── test_modeling_tf_bert.py\n",
      "│       │   │   │   ├── test_modeling_tf_camembert.py\n",
      "│       │   │   │   ├── test_modeling_tf_common.py\n",
      "│       │   │   │   ├── test_modeling_tf_ctrl.py\n",
      "│       │   │   │   ├── test_modeling_tf_distilbert.py\n",
      "│       │   │   │   ├── test_modeling_tf_electra.py\n",
      "│       │   │   │   ├── test_modeling_tf_flaubert.py\n",
      "│       │   │   │   ├── test_modeling_tf_gpt2.py\n",
      "│       │   │   │   ├── test_modeling_tf_longformer.py\n",
      "│       │   │   │   ├── test_modeling_tf_mobilebert.py\n",
      "│       │   │   │   ├── test_modeling_tf_openai.py\n",
      "│       │   │   │   ├── test_modeling_tf_roberta.py\n",
      "│       │   │   │   ├── test_modeling_tf_t5.py\n",
      "│       │   │   │   ├── test_modeling_tf_transfo_xl.py\n",
      "│       │   │   │   ├── test_modeling_tf_xlm.py\n",
      "│       │   │   │   ├── test_modeling_tf_xlm_roberta.py\n",
      "│       │   │   │   ├── test_modeling_tf_xlnet.py\n",
      "│       │   │   │   ├── test_modeling_transfo_xl.py\n",
      "│       │   │   │   ├── test_modeling_xlm.py\n",
      "│       │   │   │   ├── test_modeling_xlm_roberta.py\n",
      "│       │   │   │   ├── test_modeling_xlnet.py\n",
      "│       │   │   │   ├── test_onnx.py\n",
      "│       │   │   │   ├── test_optimization.py\n",
      "│       │   │   │   ├── test_optimization_tf.py\n",
      "│       │   │   │   ├── test_pipelines.py\n",
      "│       │   │   │   ├── test_tokenization_albert.py\n",
      "│       │   │   │   ├── test_tokenization_auto.py\n",
      "│       │   │   │   ├── test_tokenization_bert.py\n",
      "│       │   │   │   ├── test_tokenization_bert_japanese.py\n",
      "│       │   │   │   ├── test_tokenization_common.py\n",
      "│       │   │   │   ├── test_tokenization_ctrl.py\n",
      "│       │   │   │   ├── test_tokenization_distilbert.py\n",
      "│       │   │   │   ├── test_tokenization_dpr.py\n",
      "│       │   │   │   ├── test_tokenization_fast.py\n",
      "│       │   │   │   ├── test_tokenization_gpt2.py\n",
      "│       │   │   │   ├── test_tokenization_marian.py\n",
      "│       │   │   │   ├── test_tokenization_mbart.py\n",
      "│       │   │   │   ├── test_tokenization_openai.py\n",
      "│       │   │   │   ├── test_tokenization_pegasus.py\n",
      "│       │   │   │   ├── test_tokenization_roberta.py\n",
      "│       │   │   │   ├── test_tokenization_t5.py\n",
      "│       │   │   │   ├── test_tokenization_transfo_xl.py\n",
      "│       │   │   │   ├── test_tokenization_utils.py\n",
      "│       │   │   │   ├── test_tokenization_xlm.py\n",
      "│       │   │   │   ├── test_tokenization_xlm_roberta.py\n",
      "│       │   │   │   ├── test_tokenization_xlnet.py\n",
      "│       │   │   │   ├── test_trainer.py\n",
      "│       │   │   │   └── test_trainer_distributed.py\n",
      "│       │   │   ├── utils/\n",
      "│       │   │   │   ├── check_repo.py\n",
      "│       │   │   │   ├── download_glue_data.py\n",
      "│       │   │   │   └── link_tester.py\n",
      "│       │   │   └── valohai.yaml\n",
      "│       │   ├── training.py\n",
      "│       │   └── Training_bert.ipynb\n",
      "│       └── BiLSTM_CRF_tagger/\n",
      "│           ├── .ipynb_checkpoints/\n",
      "│           │   └── training_bilstm_crf-checkpoint.ipynb\n",
      "│           ├── __pycache__/\n",
      "│           │   ├── arguments.cpython-36.pyc\n",
      "│           │   ├── logger.cpython-36.pyc\n",
      "│           │   ├── ner_model.cpython-36.pyc\n",
      "│           │   ├── testing.cpython-36.pyc\n",
      "│           │   ├── training.cpython-36.pyc\n",
      "│           │   └── utilities_for_task2.cpython-36.pyc\n",
      "│           ├── arguments.py\n",
      "│           ├── checkpoints_bilstm/\n",
      "│           │   └── ckpnt_1.0_True_True_True_False_0.3_0.001_8/\n",
      "│           │       ├── checkpoint\n",
      "│           │       ├── model.ckpt-3_temp_26289ba35b03464696edcb1c6adf4954/\n",
      "│           │       │   └── part-00000-of-00001.data-00000-of-00001.tempstate14406888868128450132\n",
      "│           │       ├── model.ckpt-6.data-00000-of-00001\n",
      "│           │       ├── model.ckpt-6.index\n",
      "│           │       ├── model.ckpt-7.data-00000-of-00001\n",
      "│           │       ├── model.ckpt-7.index\n",
      "│           │       ├── model.ckpt-8.data-00000-of-00001\n",
      "│           │       └── model.ckpt-8.index\n",
      "│           ├── log/\n",
      "│           │   ├── debug.log\n",
      "│           │   ├── debug.log.2020-09-02\n",
      "│           │   ├── debug.log.2020-09-03\n",
      "│           │   ├── error.log\n",
      "│           │   ├── info.log\n",
      "│           │   ├── info.log.2020-09-02\n",
      "│           │   ├── info.log.2020-09-03\n",
      "│           │   └── warn.log\n",
      "│           ├── logger.py\n",
      "│           ├── ner_model.py\n",
      "│           ├── testing.py\n",
      "│           ├── testing.xlsx\n",
      "│           ├── training.py\n",
      "│           ├── training_bilstm_crf.ipynb\n",
      "│           ├── utilities_for_task2.py\n",
      "│           └── vocublary/\n",
      "│               ├── .ipynb_checkpoints/\n",
      "│               └── matrix_vocs.pickle\n",
      "├── raw_data/\n",
      "│   ├── .ipynb_checkpoints/\n",
      "│   ├── dataset_for_task1/\n",
      "│   │   ├── .ipynb_checkpoints/\n",
      "│   │   ├── training_set_1_tweets.txt\n",
      "│   │   ├── training_set_2_tweets.txt\n",
      "│   │   └── training_set_3_tweets.txt\n",
      "│   └── dataset_for_task2/\n",
      "│       ├── .ipynb_checkpoints/\n",
      "│       ├── task2_dataset.tsv\n",
      "│       ├── TrainData1.tsv\n",
      "│       ├── TrainData2.tsv\n",
      "│       ├── TrainData3.tsv\n",
      "│       └── TrainData4.tsv\n",
      "└── README\n"
     ]
    }
   ],
   "source": [
    "paths = DisplayablePath.make_tree(Path('AE_DETECTION_FINAL_INTERFACE'))\n",
    "for path in paths:\n",
    "    print(path.displayable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
